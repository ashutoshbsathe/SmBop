{'_beam_encoder._transformer.layers.0.linear1.bias': torch.Size([1024]),
 '_beam_encoder._transformer.layers.0.linear1.weight': torch.Size([1024, 256]),
 '_beam_encoder._transformer.layers.0.linear2.bias': torch.Size([256]),
 '_beam_encoder._transformer.layers.0.linear2.weight': torch.Size([256, 1024]),
 '_beam_encoder._transformer.layers.0.norm1.bias': torch.Size([256]),
 '_beam_encoder._transformer.layers.0.norm1.weight': torch.Size([256]),
 '_beam_encoder._transformer.layers.0.norm2.bias': torch.Size([256]),
 '_beam_encoder._transformer.layers.0.norm2.weight': torch.Size([256]),
 '_beam_encoder._transformer.layers.0.self_attn.in_proj_bias': torch.Size([768]),
 '_beam_encoder._transformer.layers.0.self_attn.in_proj_weight': torch.Size([768, 256]),
 '_beam_encoder._transformer.layers.0.self_attn.out_proj.bias': torch.Size([256]),
 '_beam_encoder._transformer.layers.0.self_attn.out_proj.weight': torch.Size([256, 256]),
 '_beam_summarizer._transformer.layers.0.linear1.bias': torch.Size([1024]),
 '_beam_summarizer._transformer.layers.0.linear1.weight': torch.Size([1024, 256]),
 '_beam_summarizer._transformer.layers.0.linear2.bias': torch.Size([256]),
 '_beam_summarizer._transformer.layers.0.linear2.weight': torch.Size([256, 1024]),
 '_beam_summarizer._transformer.layers.0.norm1.bias': torch.Size([256]),
 '_beam_summarizer._transformer.layers.0.norm1.weight': torch.Size([256]),
 '_beam_summarizer._transformer.layers.0.norm2.bias': torch.Size([256]),
 '_beam_summarizer._transformer.layers.0.norm2.weight': torch.Size([256]),
 '_beam_summarizer._transformer.layers.0.self_attn.in_proj_bias': torch.Size([768]),
 '_beam_summarizer._transformer.layers.0.self_attn.in_proj_weight': torch.Size([768, 256]),
 '_beam_summarizer._transformer.layers.0.self_attn.out_proj.bias': torch.Size([256]),
 '_beam_summarizer._transformer.layers.0.self_attn.out_proj.weight': torch.Size([256, 256]),
 '_emb_to_action_dim.bias': torch.Size([256]),
 '_emb_to_action_dim.weight': torch.Size([256, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight': torch.Size([514, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.embeddings.position_ids': torch.Size([1, 514]),
 '_question_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight': torch.Size([1, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight': torch.Size([50265, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight': torch.Size([1024, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias': torch.Size([4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight': torch.Size([4096, 1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight': torch.Size([1024, 4096]),
 '_question_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias': torch.Size([1024]),
 '_question_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight': torch.Size([1024, 1024]),
 '_rank_beam.0.bias': torch.Size([512]),
 '_rank_beam.0.weight': torch.Size([512, 512]),
 '_rank_beam.2.bias': torch.Size([512]),
 '_rank_beam.2.weight': torch.Size([512]),
 '_rank_beam.4.bias': torch.Size([1]),
 '_rank_beam.4.weight': torch.Size([1, 512]),
 '_rank_schema.0.bias': torch.Size([256]),
 '_rank_schema.0.weight': torch.Size([256, 256]),
 '_rank_schema.2.bias': torch.Size([256]),
 '_rank_schema.2.weight': torch.Size([256]),
 '_rank_schema.4.bias': torch.Size([1]),
 '_rank_schema.4.weight': torch.Size([1, 256]),
 '_schema_encoder.encoder.layers.0.feed_forward.w_1.bias': torch.Size([1024]),
 '_schema_encoder.encoder.layers.0.feed_forward.w_1.weight': torch.Size([1024, 256]),
 '_schema_encoder.encoder.layers.0.feed_forward.w_2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.0.feed_forward.w_2.weight': torch.Size([256, 1024]),
 '_schema_encoder.encoder.layers.0.relation_k_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.0.relation_v_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.0.self_attn.linears.0.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.0.self_attn.linears.0.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.0.self_attn.linears.1.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.0.self_attn.linears.1.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.0.self_attn.linears.2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.0.self_attn.linears.2.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.0.self_attn.linears.3.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.0.self_attn.linears.3.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.0.sublayer.0.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.0.sublayer.0.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.0.sublayer.1.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.0.sublayer.1.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.1.feed_forward.w_1.bias': torch.Size([1024]),
 '_schema_encoder.encoder.layers.1.feed_forward.w_1.weight': torch.Size([1024, 256]),
 '_schema_encoder.encoder.layers.1.feed_forward.w_2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.1.feed_forward.w_2.weight': torch.Size([256, 1024]),
 '_schema_encoder.encoder.layers.1.relation_k_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.1.relation_v_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.1.self_attn.linears.0.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.1.self_attn.linears.0.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.1.self_attn.linears.1.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.1.self_attn.linears.1.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.1.self_attn.linears.2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.1.self_attn.linears.2.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.1.self_attn.linears.3.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.1.self_attn.linears.3.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.1.sublayer.0.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.1.sublayer.0.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.1.sublayer.1.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.1.sublayer.1.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.2.feed_forward.w_1.bias': torch.Size([1024]),
 '_schema_encoder.encoder.layers.2.feed_forward.w_1.weight': torch.Size([1024, 256]),
 '_schema_encoder.encoder.layers.2.feed_forward.w_2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.2.feed_forward.w_2.weight': torch.Size([256, 1024]),
 '_schema_encoder.encoder.layers.2.relation_k_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.2.relation_v_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.2.self_attn.linears.0.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.2.self_attn.linears.0.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.2.self_attn.linears.1.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.2.self_attn.linears.1.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.2.self_attn.linears.2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.2.self_attn.linears.2.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.2.self_attn.linears.3.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.2.self_attn.linears.3.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.2.sublayer.0.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.2.sublayer.0.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.2.sublayer.1.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.2.sublayer.1.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.3.feed_forward.w_1.bias': torch.Size([1024]),
 '_schema_encoder.encoder.layers.3.feed_forward.w_1.weight': torch.Size([1024, 256]),
 '_schema_encoder.encoder.layers.3.feed_forward.w_2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.3.feed_forward.w_2.weight': torch.Size([256, 1024]),
 '_schema_encoder.encoder.layers.3.relation_k_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.3.relation_v_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.3.self_attn.linears.0.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.3.self_attn.linears.0.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.3.self_attn.linears.1.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.3.self_attn.linears.1.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.3.self_attn.linears.2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.3.self_attn.linears.2.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.3.self_attn.linears.3.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.3.self_attn.linears.3.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.3.sublayer.0.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.3.sublayer.0.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.3.sublayer.1.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.3.sublayer.1.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.4.feed_forward.w_1.bias': torch.Size([1024]),
 '_schema_encoder.encoder.layers.4.feed_forward.w_1.weight': torch.Size([1024, 256]),
 '_schema_encoder.encoder.layers.4.feed_forward.w_2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.4.feed_forward.w_2.weight': torch.Size([256, 1024]),
 '_schema_encoder.encoder.layers.4.relation_k_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.4.relation_v_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.4.self_attn.linears.0.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.4.self_attn.linears.0.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.4.self_attn.linears.1.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.4.self_attn.linears.1.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.4.self_attn.linears.2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.4.self_attn.linears.2.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.4.self_attn.linears.3.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.4.self_attn.linears.3.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.4.sublayer.0.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.4.sublayer.0.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.4.sublayer.1.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.4.sublayer.1.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.5.feed_forward.w_1.bias': torch.Size([1024]),
 '_schema_encoder.encoder.layers.5.feed_forward.w_1.weight': torch.Size([1024, 256]),
 '_schema_encoder.encoder.layers.5.feed_forward.w_2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.5.feed_forward.w_2.weight': torch.Size([256, 1024]),
 '_schema_encoder.encoder.layers.5.relation_k_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.5.relation_v_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.5.self_attn.linears.0.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.5.self_attn.linears.0.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.5.self_attn.linears.1.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.5.self_attn.linears.1.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.5.self_attn.linears.2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.5.self_attn.linears.2.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.5.self_attn.linears.3.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.5.self_attn.linears.3.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.5.sublayer.0.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.5.sublayer.0.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.5.sublayer.1.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.5.sublayer.1.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.6.feed_forward.w_1.bias': torch.Size([1024]),
 '_schema_encoder.encoder.layers.6.feed_forward.w_1.weight': torch.Size([1024, 256]),
 '_schema_encoder.encoder.layers.6.feed_forward.w_2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.6.feed_forward.w_2.weight': torch.Size([256, 1024]),
 '_schema_encoder.encoder.layers.6.relation_k_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.6.relation_v_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.6.self_attn.linears.0.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.6.self_attn.linears.0.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.6.self_attn.linears.1.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.6.self_attn.linears.1.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.6.self_attn.linears.2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.6.self_attn.linears.2.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.6.self_attn.linears.3.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.6.self_attn.linears.3.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.6.sublayer.0.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.6.sublayer.0.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.6.sublayer.1.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.6.sublayer.1.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.7.feed_forward.w_1.bias': torch.Size([1024]),
 '_schema_encoder.encoder.layers.7.feed_forward.w_1.weight': torch.Size([1024, 256]),
 '_schema_encoder.encoder.layers.7.feed_forward.w_2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.7.feed_forward.w_2.weight': torch.Size([256, 1024]),
 '_schema_encoder.encoder.layers.7.relation_k_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.7.relation_v_emb.weight': torch.Size([51, 32]),
 '_schema_encoder.encoder.layers.7.self_attn.linears.0.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.7.self_attn.linears.0.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.7.self_attn.linears.1.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.7.self_attn.linears.1.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.7.self_attn.linears.2.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.7.self_attn.linears.2.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.7.self_attn.linears.3.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.7.self_attn.linears.3.weight': torch.Size([256, 256]),
 '_schema_encoder.encoder.layers.7.sublayer.0.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.7.sublayer.0.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.layers.7.sublayer.1.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.layers.7.sublayer.1.norm.weight': torch.Size([256]),
 '_schema_encoder.encoder.norm.bias': torch.Size([256]),
 '_schema_encoder.encoder.norm.weight': torch.Size([256]),
 '_span_score_func.bias': torch.Size([2]),
 '_span_score_func.weight': torch.Size([2, 256]),
 '_tree_rep_transformer._positional_embedding.weight': torch.Size([512, 256]),
 '_tree_rep_transformer._transformer.layers.0.linear1.bias': torch.Size([1024]),
 '_tree_rep_transformer._transformer.layers.0.linear1.weight': torch.Size([1024, 256]),
 '_tree_rep_transformer._transformer.layers.0.linear2.bias': torch.Size([256]),
 '_tree_rep_transformer._transformer.layers.0.linear2.weight': torch.Size([256, 1024]),
 '_tree_rep_transformer._transformer.layers.0.norm1.bias': torch.Size([256]),
 '_tree_rep_transformer._transformer.layers.0.norm1.weight': torch.Size([256]),
 '_tree_rep_transformer._transformer.layers.0.norm2.bias': torch.Size([256]),
 '_tree_rep_transformer._transformer.layers.0.norm2.weight': torch.Size([256]),
 '_tree_rep_transformer._transformer.layers.0.self_attn.in_proj_bias': torch.Size([768]),
 '_tree_rep_transformer._transformer.layers.0.self_attn.in_proj_weight': torch.Size([768, 256]),
 '_tree_rep_transformer._transformer.layers.0.self_attn.out_proj.bias': torch.Size([256]),
 '_tree_rep_transformer._transformer.layers.0.self_attn.out_proj.weight': torch.Size([256, 256]),
 '_unary_frontier_embedder.0.bias': torch.Size([512]),
 '_unary_frontier_embedder.0.weight': torch.Size([512, 512]),
 '_unary_frontier_embedder.2.bias': torch.Size([512]),
 '_unary_frontier_embedder.2.weight': torch.Size([512]),
 '_unary_frontier_embedder.4.bias': torch.Size([512]),
 '_unary_frontier_embedder.4.weight': torch.Size([512, 512]),
 '_utterance_augmenter.att.key.bias': torch.Size([256]),
 '_utterance_augmenter.att.key.weight': torch.Size([256, 256]),
 '_utterance_augmenter.att.query.bias': torch.Size([256]),
 '_utterance_augmenter.att.query.weight': torch.Size([256, 256]),
 '_utterance_augmenter.att.value.bias': torch.Size([256]),
 '_utterance_augmenter.att.value.weight': torch.Size([256, 256]),
 '_utterance_augmenter.output.LayerNorm.bias': torch.Size([256]),
 '_utterance_augmenter.output.LayerNorm.weight': torch.Size([256]),
 '_utterance_augmenter.output.dense.bias': torch.Size([256]),
 '_utterance_augmenter.output.dense.weight': torch.Size([256, 256]),
 'after_add.0.bias': torch.Size([512]),
 'after_add.0.weight': torch.Size([512, 512]),
 'after_add.2.bias': torch.Size([512]),
 'after_add.2.weight': torch.Size([512]),
 'after_add.4.bias': torch.Size([512]),
 'after_add.4.weight': torch.Size([512, 512]),
 'left_emb.bias': torch.Size([512]),
 'left_emb.weight': torch.Size([512, 512]),
 'op_linear.bias': torch.Size([34]),
 'op_linear.weight': torch.Size([34, 512]),
 'pre_op_linear.0.bias': torch.Size([512]),
 'pre_op_linear.0.weight': torch.Size([512, 512]),
 'pre_op_linear.2.bias': torch.Size([512]),
 'pre_op_linear.2.weight': torch.Size([512]),
 'right_emb.bias': torch.Size([512]),
 'right_emb.weight': torch.Size([512, 512]),
 'summrize_vec.weight': torch.Size([1, 256]),
 'type_embedding.weight': torch.Size([34, 256])}